{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "from model import *\n",
    "from defaultParameter import*\n",
    "from utils import *\n",
    "from random import randint, shuffle\n",
    "from train import getTrainSet\n",
    "\n",
    "testSet, label2IndexRumor, label2IndexStance = getTrainSet('../dataset/semeval2017-task8/')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = MTUS(numRumorClass=len(label2IndexRumor), numStanceClass=len(label2IndexStance))\n",
    "model.load_state_dict(torch.load())\n",
    "model = model.set_device(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "rumorTrue = []\n",
    "stanceTrue = []\n",
    "rumorPre = []\n",
    "stancePre = []\n",
    "totalLossRumor = 0.\n",
    "totalLossStance = 0.\n",
    "for i in range(len(testSet)):\n",
    "    x = testSet[i][0].to(device)\n",
    "    rumorTag = testSet[i][1].to(device)\n",
    "    stanceTag = testSet[i][2].to(device)\n",
    "    rumorTrue += testSet[i][1].tolist()\n",
    "    stanceTrue += testSet[i][2].tolist()\n",
    "\n",
    "    pRumor = model.forwardRumor(x)\n",
    "    pStance = model.forwardStance(x).view(-1, len(label2IndexStance))\n",
    "    loss = loss_func(pRumor, rumorTag)\n",
    "    totalLossRumor += loss\n",
    "    loss = loss_func(pStance, stanceTag)\n",
    "    totalLossStance += loss\n",
    "    pRumor = softmax(pRumor, 1)\n",
    "    rumorPre += pRumor.max(dim=1)[1].tolist()\n",
    "    pStance = softmax(pStance, 1)\n",
    "    stancePre += pStance.max(dim=1)[1].tolist()\n",
    "\n",
    "microF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='micro')\n",
    "macroF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='macro')\n",
    "microF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2], average='micro')\n",
    "macroF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2], average='macro')\n",
    "accuracyRumor = (np.array(rumorTrue) == np.array(rumorPre)).sum() / len(rumorPre)\n",
    "accuracyStance = (np.array(stanceTrue) == np.array(stancePre)).sum() / len(stancePre)\n",
    "print('rumor detection:')\n",
    "print('average loss: {:f}, accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    totalLossRumor / len(testSet), accuracyRumor, microF1Rumor, macroF1Rumor\n",
    "))\n",
    "print('stance analyze:')\n",
    "print('average loss: {:f}, accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    totalLossStance / len(testSet), accuracyStance, microF1Stance, macroF1Stance\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
