{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.functional import softmax\n",
    "from model import *\n",
    "from defaultParameter import*\n",
    "from utils import *\n",
    "\n",
    "with open('../dataset/semeval2017-task8/' + 'trainSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "trainSet = json.loads(content)\n",
    "threads = []\n",
    "rumorTags = []\n",
    "stanceTags = []\n",
    "for threadId in trainSet['threadIds']:\n",
    "    thread = []\n",
    "    stanceTag = []\n",
    "    structure = trainSet['structures'][threadId]\n",
    "    ids = flattenStructure(structure)\n",
    "    time2Id = {}\n",
    "    for id in ids:\n",
    "        if id in trainSet['posts']:\n",
    "            time2Id[str(trainSet['posts'][id]['time'])] = id\n",
    "    # post按照时间先后排序\n",
    "    time2Id = sorted(time2Id.items(), key=lambda d: d[0])\n",
    "    for (time, id) in time2Id:\n",
    "        if id in trainSet['posts'] and id in trainSet['stanceTag']:\n",
    "            thread.append(trainSet['posts'][id]['text'])\n",
    "            stanceTag.append(trainSet['label2IndexStance'][trainSet['stanceTag'][id]])\n",
    "    threads.append(thread)\n",
    "    rumorTags.append(torch.LongTensor([trainSet['label2IndexRumor'][trainSet['rumorTag'][threadId]]]))\n",
    "    stanceTags.append(torch.LongTensor(stanceTag))\n",
    "cropus = []\n",
    "for thread in threads:\n",
    "    for text in thread:\n",
    "        cropus.append(text)\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(cropus) # 使用train set训练一个tfidf向量化转换器\n",
    "label2IndexRumor = trainSet['label2IndexRumor']\n",
    "label2IndexStance = trainSet['label2IndexStance']\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = MTUS(embeddingDim=100, hiddenDim=100, inputDim=tfidf_matrix.shape[1], numGRULayer=2,\n",
    "             numRumorClass=len(label2IndexRumor), numStanceClass=len(label2IndexStance))\n",
    "model.load_state_dict(torch.load('./model.pt', map_location=device))\n",
    "model = model.set_device(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/semeval2017-task8/' + 'testSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "testSet = json.loads(content)\n",
    "threads = []\n",
    "rumorTags = []\n",
    "stanceTags = []\n",
    "for threadId in testSet['threadIds']:\n",
    "    thread = []\n",
    "    stanceTag = []\n",
    "    structure = testSet['structures'][threadId]\n",
    "    ids = flattenStructure(structure)\n",
    "    time2Id = {}\n",
    "    for id in ids:\n",
    "        if id in testSet['posts']:\n",
    "            time2Id[str(testSet['posts'][id]['time'])] = id\n",
    "    # post按照时间先后排序\n",
    "    time2Id = sorted(time2Id.items(), key=lambda d: d[0])\n",
    "    for (time, id) in time2Id:\n",
    "        if id in testSet['posts'] and id in testSet['stanceTag']:\n",
    "            thread.append(testSet['posts'][id]['text'])\n",
    "            stanceTag.append(testSet['label2IndexStance'][testSet['stanceTag'][id]])\n",
    "    threads.append(thread)\n",
    "    rumorTags.append(torch.LongTensor([testSet['label2IndexRumor'][testSet['rumorTag'][threadId]]]))\n",
    "    stanceTags.append(torch.LongTensor(stanceTag))\n",
    "cropus = []\n",
    "for thread in threads:\n",
    "    for text in thread:\n",
    "        cropus.append(text)\n",
    "tfidf_matrix = tfidf_vec.transform(cropus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(len(threads)):\n",
    "    tfidf = []\n",
    "    for _ in threads[i]:\n",
    "        tfidf.append(tfidf_matrix[counter])\n",
    "        counter += 1\n",
    "    threads[i] = torch.Tensor(tfidf)\n",
    "\n",
    "label2IndexRumor = testSet['label2IndexRumor']\n",
    "label2IndexStance = testSet['label2IndexStance']\n",
    "testSet = []\n",
    "for i in range(len(threads)):\n",
    "    testSet.append((threads[i], rumorTags[i], stanceTags[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor detection:\n",
      "average loss: 1.472029, accuracy: 0.321429, micro-f1: 0.321429, macro-f1: 0.271912\n",
      "stance analyze:\n",
      "average loss: 164.627884, accuracy: 0.584130, micro-f1: 0.145390, macro-f1: 0.131475\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "rumorTrue = []\n",
    "stanceTrue = []\n",
    "rumorPre = []\n",
    "stancePre = []\n",
    "totalLossRumor = 0.\n",
    "totalLossStance = 0.\n",
    "for i in range(len(testSet)):\n",
    "    x = testSet[i][0].to(device)\n",
    "    rumorTag = testSet[i][1].to(device)\n",
    "    stanceTag = testSet[i][2].to(device)\n",
    "    rumorTrue += testSet[i][1].tolist()\n",
    "    stanceTrue += testSet[i][2].tolist()\n",
    "\n",
    "    pRumor = model.forwardRumor(x)\n",
    "    pStance = model.forwardStance(x).view(-1, len(label2IndexStance))\n",
    "    loss = loss_func(pRumor, rumorTag)\n",
    "    totalLossRumor += loss\n",
    "    loss = loss_func(pStance, stanceTag)\n",
    "    totalLossStance += loss\n",
    "    pRumor = softmax(pRumor, 1)\n",
    "    rumorPre += pRumor.max(dim=1)[1].tolist()\n",
    "    pStance = softmax(pStance, 1)\n",
    "    stancePre += pStance.max(dim=1)[1].tolist()\n",
    "\n",
    "microF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='micro')\n",
    "macroF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='macro')\n",
    "microF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2], average='micro')\n",
    "macroF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2], average='macro')\n",
    "accuracyRumor = (np.array(rumorTrue) == np.array(rumorPre)).sum() / len(rumorPre)\n",
    "accuracyStance = (np.array(stanceTrue) == np.array(stancePre)).sum() / len(stancePre)\n",
    "print('rumor detection:')\n",
    "print('average loss: {:f}, accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    totalLossRumor / len(testSet), accuracyRumor, microF1Rumor, macroF1Rumor\n",
    "))\n",
    "print('stance analyze:')\n",
    "print('average loss: {:f}, accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    totalLossStance / len(testSet), accuracyStance, microF1Stance, macroF1Stance\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7643d6338a47b6278c24a646f58c2f1853e9cc5d84629549f0ec76d46f16ce0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
