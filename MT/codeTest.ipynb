{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from data import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from model import *\n",
    "from utils import *\n",
    "from random import randint, shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '../dataset/PHEME/'\n",
    "\n",
    "tfidf_vec, label2IndexRumor, label2IndexStance = getTfidfAndLabel(dataPath)\n",
    "inputDim = tfidf_vec.max_features\n",
    "\n",
    "trainSet = PHEMEDataset(\n",
    "    dataPath = dataPath, \n",
    "    type = 'train'\n",
    ")\n",
    "testSet = PHEMEDataset(\n",
    "    dataPath = dataPath,\n",
    "    type = 'test'\n",
    ")\n",
    "# trainSet = semEval2017Dataset(\n",
    "#     dataPath = dataPath, \n",
    "#     type = 'train'\n",
    "# )\n",
    "# testSet = semEval2017Dataset(\n",
    "#     dataPath = dataPath,\n",
    "#     type = 'test'\n",
    "# )\n",
    "trainLoader = DataLoader(trainSet, collate_fn=collate, shuffle=True)\n",
    "testLoader = DataLoader(testSet, collate_fn=collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = MTUS(\n",
    "    embeddingDim=100, \n",
    "    hiddenDim=100,\n",
    "    inputDim=inputDim, \n",
    "    numGRULayer=1,\n",
    "    numRumorClass=len(label2IndexRumor),\n",
    "    numStanceClass=len(label2IndexStance) if label2IndexStance != None else 4\n",
    ")\n",
    "model.set_device(device)\n",
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4,weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "for epoch in range(start, start + 1):\n",
    "    model.train()\n",
    "    totalLoss = 0.\n",
    "    rumorTrue = []\n",
    "    rumorPre = []\n",
    "    for thread in trainLoader:\n",
    "        #post = tfidf_vec.transform(thread['thread']).toarray()\n",
    "        posts = torch.Tensor(tfidf_vec.transform(thread['thread']).toarray()).to(device)\n",
    "        rumorTrue += thread['rumorTag'].tolist()\n",
    "        rumorTag = thread['rumorTag'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p = model.forwardRumor(posts)\n",
    "        loss = loss_func(p, rumorTag)\n",
    "        totalLoss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        p = softmax(p, 1)\n",
    "        rumorPre += p.max(dim=1)[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55, 5000])\n",
      "tensor([[-0.1444, -0.3136,  0.0930,  0.3046],\n",
      "        [-0.0190, -0.1767,  0.0787,  0.3317],\n",
      "        [ 0.0487, -0.1463,  0.0595,  0.2973],\n",
      "        [ 0.0882, -0.1504,  0.0474,  0.2594],\n",
      "        [ 0.1061, -0.1638,  0.0460,  0.2342],\n",
      "        [ 0.1186, -0.1774,  0.0469,  0.2159],\n",
      "        [ 0.1179, -0.1863,  0.0481,  0.2091],\n",
      "        [ 0.1203, -0.1917,  0.0523,  0.2046],\n",
      "        [ 0.1203, -0.1964,  0.0522,  0.2015],\n",
      "        [ 0.1175, -0.2037,  0.0528,  0.1959],\n",
      "        [ 0.1174, -0.2035,  0.0542,  0.1970],\n",
      "        [ 0.1170, -0.2083,  0.0538,  0.1917],\n",
      "        [ 0.1160, -0.2087,  0.0535,  0.1913],\n",
      "        [ 0.1146, -0.2134,  0.0544,  0.1877],\n",
      "        [ 0.1137, -0.2115,  0.0547,  0.1895],\n",
      "        [ 0.1146, -0.2174,  0.0568,  0.1822],\n",
      "        [ 0.1149, -0.2158,  0.0558,  0.1880],\n",
      "        [ 0.1137, -0.2152,  0.0547,  0.1870],\n",
      "        [ 0.1132, -0.2146,  0.0554,  0.1862],\n",
      "        [ 0.1124, -0.2156,  0.0547,  0.1873],\n",
      "        [ 0.1094, -0.2136,  0.0557,  0.1910],\n",
      "        [ 0.1108, -0.2147,  0.0556,  0.1898],\n",
      "        [ 0.1108, -0.2158,  0.0550,  0.1871],\n",
      "        [ 0.1121, -0.2140,  0.0555,  0.1891],\n",
      "        [ 0.1132, -0.2171,  0.0560,  0.1850],\n",
      "        [ 0.1102, -0.2142,  0.0565,  0.1919],\n",
      "        [ 0.1104, -0.2149,  0.0568,  0.1911],\n",
      "        [ 0.1134, -0.2131,  0.0572,  0.1910],\n",
      "        [ 0.1102, -0.2122,  0.0564,  0.1929],\n",
      "        [ 0.1094, -0.2103,  0.0554,  0.1946],\n",
      "        [ 0.1124, -0.2123,  0.0560,  0.1910],\n",
      "        [ 0.1119, -0.2123,  0.0550,  0.1908],\n",
      "        [ 0.1128, -0.2139,  0.0555,  0.1899],\n",
      "        [ 0.1087, -0.2136,  0.0558,  0.1922],\n",
      "        [ 0.1107, -0.2177,  0.0575,  0.1881],\n",
      "        [ 0.1094, -0.2139,  0.0563,  0.1908],\n",
      "        [ 0.1104, -0.2117,  0.0557,  0.1911],\n",
      "        [ 0.1170, -0.2133,  0.0550,  0.1884],\n",
      "        [ 0.1168, -0.2155,  0.0540,  0.1880],\n",
      "        [ 0.1163, -0.2134,  0.0557,  0.1915],\n",
      "        [ 0.1179, -0.2146,  0.0557,  0.1878],\n",
      "        [ 0.1151, -0.2120,  0.0541,  0.1901],\n",
      "        [ 0.1178, -0.2115,  0.0567,  0.1907],\n",
      "        [ 0.1158, -0.2102,  0.0541,  0.1914],\n",
      "        [ 0.1165, -0.2110,  0.0555,  0.1899],\n",
      "        [ 0.1137, -0.2109,  0.0554,  0.1928],\n",
      "        [ 0.1147, -0.2116,  0.0558,  0.1914],\n",
      "        [ 0.1162, -0.2127,  0.0555,  0.1885],\n",
      "        [ 0.1127, -0.2123,  0.0542,  0.1915],\n",
      "        [ 0.1143, -0.2153,  0.0552,  0.1881],\n",
      "        [ 0.1162, -0.2137,  0.0561,  0.1917],\n",
      "        [ 0.1158, -0.2140,  0.0562,  0.1898],\n",
      "        [ 0.1152, -0.2165,  0.0557,  0.1876],\n",
      "        [ 0.1145, -0.2135,  0.0562,  0.1911],\n",
      "        [ 0.1167, -0.2149,  0.0567,  0.1863]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "for epoch in range(start, start + 1):\n",
    "    model.train()\n",
    "    totalLoss = 0.\n",
    "    stanceTrue = []\n",
    "    stancePre = []\n",
    "    for thread in trainLoader:\n",
    "        posts = torch.Tensor(tfidf_vec.transform(thread['thread']).toarray()).to(device)\n",
    "        stanceTrue += thread['stanceTag'].tolist()\n",
    "        stanceTag = thread['stanceTag'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p = model.forwardStance(posts)\n",
    "        loss = loss_func(p, stanceTag)\n",
    "        totalLoss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        p = softmax(p, 1)\n",
    "        #stancePre += p.max(dim=1)[1].tolist()\n",
    "        print(p.max(dim=1)[1].tolist())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "y_true = np.array([0,1,2,2,1,0])\n",
    "y_pred = np.array([0,0,0,1,0,1])\n",
    "(y_true == y_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
