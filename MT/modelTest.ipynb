{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataSetPath = '../dataset/semeval2017-task8/'\n",
    "with open(dataSetPath + 'trainSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "trainSet = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "trainSet = json.loads(content)\n",
    "threads = []\n",
    "rumorTags = []\n",
    "stanceTags = []\n",
    "for threadId in trainSet['threadIds']:\n",
    "    thread = []\n",
    "    stanceTag = []\n",
    "    structure = trainSet['structures'][threadId]\n",
    "    ids = flattenStructure(structure)\n",
    "    time2Id = {}\n",
    "    for id in ids:\n",
    "        if id in trainSet['posts']:\n",
    "            time2Id[str(trainSet['posts'][id]['time'])] = id\n",
    "    # post按照时间先后排序\n",
    "    time2Id = sorted(time2Id.items(), key=lambda d: d[0])\n",
    "    for (time, id) in time2Id:\n",
    "        if id in trainSet['posts'] and id in trainSet['stanceTag']:\n",
    "            thread.append(trainSet['posts'][id]['text'])\n",
    "            stanceTag.append(trainSet['label2IndexStance'][trainSet['stanceTag'][id]])\n",
    "    threads.append(thread)\n",
    "    rumorTags.append(torch.LongTensor([trainSet['label2IndexRumor'][trainSet['rumorTag'][threadId]]]))\n",
    "    stanceTags.append(torch.LongTensor(stanceTag))\n",
    "cropus = []\n",
    "for thread in threads:\n",
    "    for text in thread:\n",
    "        cropus.append(text)\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(cropus).toarray()\n",
    "counter = 0\n",
    "for i in range(len(threads)):\n",
    "    tfidf = []\n",
    "    for _ in threads[i]:\n",
    "        tfidf.append(tfidf_matrix[counter])\n",
    "        counter += 1\n",
    "    threads[i] = torch.Tensor(tfidf)\n",
    "\n",
    "label2IndexRumor = trainSet['label2IndexRumor']\n",
    "label2IndexStance = trainSet['label2IndexStance']\n",
    "trainSet = []\n",
    "for i in range(len(threads)):\n",
    "    trainSet.append((threads[i], rumorTags[i], stanceTags[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class MTUS(nn.Module):\n",
    "    def __init__(self, embeddingDim: int, hiddenDim: int, inputDim: int, \n",
    "                 numGRULayer: int, numRumorClass: int, numStanceClass: int,\n",
    "                 batchSize = 1, bidirectional = False):\n",
    "        super().__init__() # 调用nn.Moudle父类的初始化方法\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 优先使用cuda\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.batchSize = batchSize\n",
    "        self.bidirectional = bidirectional\n",
    "        self.D = 2 if self.bidirectional else 1\n",
    "        \n",
    "        # embedding使用线性层来把tf-idf向量转换成句嵌入\n",
    "        self.embeddingRumor = nn.Linear(inputDim, embeddingDim)\n",
    "        self.embeddingStance = nn.Linear(inputDim, embeddingDim)\n",
    "        \n",
    "        # 共享GRU层\n",
    "        self.shareGRU = nn.GRU(embeddingDim, hiddenDim, numGRULayer, bidirectional = self.bidirectional)\n",
    "        self.h0 = nn.Parameter(torch.randn((self.D * numGRULayer, self.batchSize, hiddenDim)))\n",
    "\n",
    "        # 把GRU的隐状态映射成概率\n",
    "        self.vRumor = nn.Linear(self.D * hiddenDim, numRumorClass)\n",
    "        self.vStance = nn.Linear(self.D * 2 * hiddenDim, numStanceClass) # stance的预测需要拼接第一句的隐状态\n",
    "        \n",
    "    # 训练集前向传递，返回对特定任务的概率向量/矩阵\n",
    "    def forwardRumor(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0] # 取tensor size的第一维，是本次训练的thread的长度\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim) # view是为了适配gru的输入样式\n",
    "        # hs(seqLen, batch, numDirection * hiddenDim), ht(numLayers*numDirections, batch, hiddenDim)\n",
    "        # 舍弃掉ht的输出是因为下一个thread和这次训练的thread是独立的，不应该用本次的隐状态作为其h0输入\n",
    "        gruOut, _ = self.shareGRU(embeddings, self.h0) \n",
    "        ht = gruOut[gruOut.size()[0] - 1].view(self.batchSize, self.D * self.hiddenDim) # 取出最后一层的隐状态\n",
    "        p = self.vRumor(ht)\n",
    "        return p # 返回的概率矩阵是包含batch维度的size():(batch, numDirection)\n",
    "    \n",
    "    def forwardStance(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0]\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim)\n",
    "        gruOut, _ = self.shareGRU(embeddings, self.h0) # hs(seqLen, batch, numDirection * hiddenDim)\n",
    "        h1Repeat = gruOut[0].repeat(seqLen, 1, 1) # h1Repeat(seqLen, batch, numDirection * hiddenDim)\n",
    "        p = self.vStance(torch.cat([h1Repeat, gruOut], dim=2))\n",
    "        return p\n",
    "\n",
    "    # 更换计算设备\n",
    "    def set_device(self, device: torch.device) -> torch.nn.Module:\n",
    "        _model = self.to(device)\n",
    "        _model.device = device\n",
    "        return _model\n",
    "\n",
    "    # 保存模型\n",
    "    def save(self, path: str):\n",
    "        pass\n",
    "    # 加载模型\n",
    "    def load(self, path: str):\n",
    "        pass\n",
    "    \n",
    "mtus = MTUS(embeddingDim=100, hiddenDim=100, inputDim=threads[0].size()[1],\n",
    "            numGRULayer=2, numRumorClass=3, numStanceClass=4, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adagrad(mtus.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6586]) torch.Size([1]) torch.Size([5])\n",
      "torch.Size([1, 3]) tensor([0])\n",
      "tensor([[0.3227, 0.3302, 0.3471]], grad_fn=<SoftmaxBackward>)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#rumor test\n",
    "x = threads[0]\n",
    "rumorTag = rumorTags[0]\n",
    "stanceTag = stanceTags[0]\n",
    "print(x.size(), rumorTag.size(), stanceTag.size())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "p1 = mtus.forwardRumor(x)\n",
    "print(p1.size(), rumorTag)\n",
    "loss = loss_func(p1, rumorTag)\n",
    "loss.backward()\n",
    "#optimizer.step()\n",
    "p1 = softmax(p1, 1)\n",
    "print(p1)\n",
    "p1 = p1.max(dim=1)[1].item()\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4]) tensor([0, 3, 3, 3, 0])\n",
      "tensor([[0.5297, 0.0167, 0.0130, 0.4406],\n",
      "        [0.2648, 0.0127, 0.0096, 0.7128],\n",
      "        [0.1875, 0.0102, 0.0079, 0.7943],\n",
      "        [0.2673, 0.0109, 0.0089, 0.7128],\n",
      "        [0.6245, 0.0136, 0.0116, 0.3503]], grad_fn=<SoftmaxBackward>)\n",
      "[0, 3, 3, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "#stance test\n",
    "optimizer.zero_grad()\n",
    "p2 = mtus.forwardStance(x).view(-1, len(trainSet['label2IndexStance']))\n",
    "print(p2.size(), stanceTag)\n",
    "loss = loss_func(p2, stanceTag)\n",
    "loss.backward()\n",
    "#optimizer.step()\n",
    "p2 = softmax(p2, 1)\n",
    "print(p2)\n",
    "p2 = p2.max(dim=1)[1].tolist()\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = [0,1,2,2,1,0]\n",
    "y_pred = [0,0,0,1,0,1]\n",
    "print(f1_score(y_true, y_pred, labels=[0,1,2], average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
