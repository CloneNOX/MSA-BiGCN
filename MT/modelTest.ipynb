{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataSetPath = '../dataset/semeval2017-task8/'\n",
    "with open(dataSetPath + 'trainSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "trainSet = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['postIds', 'stanceTag', 'threadIds', 'rumorTag', 'structures', 'posts', 'label2IndexRumor', 'label2IndexStance', 'index2LabelRumor', 'index2LabelStance'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import log\n",
    "from utils import *\n",
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "textNum = len(trainSet['posts'])\n",
    "threads = []\n",
    "rumorTags = []\n",
    "stanceTags = []\n",
    "for threadId in trainSet['threadIds']:\n",
    "    thread = {str(trainSet['posts'][threadId]['time']): trainSet['posts'][threadId]['text']}\n",
    "    structure = trainSet['structures'][threadId]\n",
    "    ids = flattenStructure(structure)\n",
    "    stanceTag = []\n",
    "    for id in ids:\n",
    "        if id in trainSet['posts']:\n",
    "            thread[str(trainSet['posts'][id]['time'])] = trainSet['posts'][id]['text']\n",
    "            stanceTag.append(trainSet['label2IndexStance'][trainSet['stanceTag'][id]])\n",
    "    # post按照时间先后排序\n",
    "    thread = sorted(thread.items(), key=lambda d: d[0])\n",
    "    threads.append(thread)\n",
    "    rumorTags.append(torch.LongTensor([trainSet['label2IndexRumor'][trainSet['rumorTag'][threadId]]]))\n",
    "    stanceTags.append(torch.LongTensor(stanceTag))\n",
    "cropus = []\n",
    "for thread in threads:\n",
    "    for _, text in thread:\n",
    "        cropus.append(text)\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(cropus).toarray()\n",
    "counter = 0\n",
    "for i in range(len(threads)):\n",
    "    tfidf = []\n",
    "    for _, _ in threads[i]:\n",
    "        tfidf.append(tfidf_matrix[counter])\n",
    "        counter += 1\n",
    "    threads[i] = torch.Tensor(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class MTUS(nn.Module):\n",
    "    def __init__(self, embeddingDim: int, hiddenDim: int, inputDim: int, \n",
    "                 numGRULayer: int, numRumorClass: int, numStanceClass: int,\n",
    "                 batchSize = 1, bidirectional = False):\n",
    "        super().__init__() # 调用nn.Moudle父类的初始化方法\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 优先使用cuda\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.batchSize = batchSize\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # embedding使用线性层来把tf-idf向量转换成句嵌入\n",
    "        self.embeddingRumor = nn.Linear(inputDim, embeddingDim)\n",
    "        self.embeddingStance = nn.Linear(inputDim, embeddingDim)\n",
    "        \n",
    "        # 共享GRU层\n",
    "        self.shareGRU = nn.GRU(embeddingDim, hiddenDim, numGRULayer, bidirectional = self.bidirectional)\n",
    "        self.h0 = nn.Parameter(torch.randn((numGRULayer, self.batchSize, hiddenDim)))\n",
    "\n",
    "        # 把GRU的隐状态映射成概率\n",
    "        self.vRumor = nn.Linear(hiddenDim, numRumorClass)\n",
    "        self.v1Stance = nn.Linear(hiddenDim, numStanceClass)\n",
    "        self.vStance = nn.Linear(hiddenDim, numStanceClass)\n",
    "\n",
    "    # 训练集前向传递，返回对特定任务的概率向量/矩阵\n",
    "    def forwardRumor(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0]\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim) # view是为了适配gru的输入样式\n",
    "        gruOut, _ = self.shareGRU(embeddings, self.h0) # hs(seqLen, batch, numDirection * hiddenDim), ht(numLayers*numDirections, batch, hiddenDim)\n",
    "        ht = gruOut[gruOut.size()[0] - 1].view(self.batchSize, self.hiddenDim) # 取出最后一层的隐状态\n",
    "        p = self.vRumor(ht)\n",
    "        return p # 返回的概率矩阵是包含batch维度的size():(batch, numDirection)\n",
    "    \n",
    "    def forwardStance(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0]\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim)\n",
    "        hs, _ = self.shareGRU(embeddings, self.h0)# hs(seqLen, batch, numDirection * hiddenDim)\n",
    "        ps = self.v1Stance(hs[0]) + self.vStance(hs)\n",
    "        return ps\n",
    "\n",
    "    # 更换计算设备\n",
    "    def set_device(self, device: torch.device) -> torch.nn.Module:\n",
    "        _model = self.to(device)\n",
    "        _model.device = device\n",
    "        return _model\n",
    "\n",
    "    # 保存模型\n",
    "    def save(self, path: str):\n",
    "        pass\n",
    "    # 加载模型\n",
    "    def load(self, path: str):\n",
    "        pass\n",
    "    \n",
    "mtus = MTUS(embeddingDim=100, hiddenDim=100, inputDim=threads[0].size()[1],\n",
    "            numGRULayer=2, numRumorClass=3, numStanceClass=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(mtus.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8539, -0.2012, -1.0214]], grad_fn=<AddmmBackward>) tensor([0]) tensor([0, 3, 3, 3, 0])\n",
      "tensor([[0.8442, 0.1081, 0.0476]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = threads[0]\n",
    "rumorTag = rumorTags[0]\n",
    "stanceTag = stanceTags[0]\n",
    "p = mtus.forwardRumor(x)\n",
    "print(p, rumorTag, stanceTag)\n",
    "loss = loss_func(p, rumorTag)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "p = softmax(p, 1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
