{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataSetPath = '../dataset/semeval2017-task8/'\n",
    "with open(dataSetPath + 'trainSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "trainSet = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['postIds', 'stanceTag', 'threadIds', 'rumorTag', 'structures', 'posts'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = {}\n",
    "for Id in trainSet['postIds']:\n",
    "    alreadyHave = []\n",
    "    for word in trainSet['posts'][Id]['text'].split(' '):\n",
    "        if word not in wordList:\n",
    "            wordList[word] = 1\n",
    "        elif word not in alreadyHave:\n",
    "            wordList[word] += 1\n",
    "        alreadyHave.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import log\n",
    "from utils import *\n",
    "textNum = len(trainSet['posts'])\n",
    "threads = []\n",
    "maxLen = 0\n",
    "rumorTags = []\n",
    "stanceTags = []\n",
    "for threadId in trainSet['threadIds']:\n",
    "    thread = {str(trainSet['posts'][threadId]['time']): trainSet['posts'][threadId]['text']}\n",
    "    structure = trainSet['structures'][threadId]\n",
    "    ids = flattenStructure(structure)\n",
    "    stanceTag = []\n",
    "    for id in ids:\n",
    "        if id in trainSet['posts']:\n",
    "            thread[str(trainSet['posts'][id]['time'])] = trainSet['posts'][id]['text']\n",
    "            maxLen = max(maxLen, len(trainSet['posts'][id]['text'].split(' ')))\n",
    "            stanceTag.append(trainSet['stanceTag'][id])\n",
    "    thread = sorted(thread.items(), key=lambda d: d[0])\n",
    "    threads.append(thread)\n",
    "    rumorTags.append(trainSet['rumorTag'][threadId])\n",
    "    stanceTags.append(stanceTag)\n",
    "for i in range(len(threads)):\n",
    "    thread = threads[i]\n",
    "    for j in range(len(thread)):\n",
    "        post = thread[j]\n",
    "        text = post[1].split(' ')\n",
    "        while len(text) < maxLen:\n",
    "            text.append('<pad>')\n",
    "        exist = {}\n",
    "        for word in text:\n",
    "            if word in exist:\n",
    "                exist[word] += 1\n",
    "            else:\n",
    "                exist[word] = 1\n",
    "        tf_idf = []\n",
    "        for word in text:\n",
    "            tf_idf.append(exist[word] / len(text) * (log(textNum / (wordList[word] + 1))))\n",
    "        thread[j] = tf_idf\n",
    "    threads[i] = torch.Tensor(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rumorTags)\n",
    "stanceTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class MTUS(nn.Module):\n",
    "    def __init__(self, embeddingDim: int, hiddenDim: int, inputDim: int, \n",
    "                 numGRULayer: int, numRumorClass: int, numStanceClass: int,\n",
    "                 batchSize = 1, bidirectional = False):\n",
    "        super().__init__() # 调用nn.Moudle父类的初始化方法\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 优先使用cuda\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.batchSize = batchSize\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # embedding使用线性层来把tf-idf向量转换成句嵌入\n",
    "        self.embeddingRumor = nn.Linear(inputDim, embeddingDim)\n",
    "        self.embeddingStance = nn.Linear(inputDim, embeddingDim)\n",
    "        \n",
    "        # 共享GRU层\n",
    "        self.shareGRU = nn.GRU(embeddingDim, hiddenDim, numGRULayer, bidirectional = self.bidirectional)\n",
    "        self.h0 = nn.Parameter(torch.randn((numGRULayer, self.batchSize, hiddenDim)))\n",
    "\n",
    "        # 把GRU的隐状态映射成概率\n",
    "        self.vRumor = nn.Linear(hiddenDim, numRumorClass)\n",
    "        self.v1Stance = nn.Linear(hiddenDim, numStanceClass)\n",
    "        self.vStance = nn.Linear(hiddenDim, numStanceClass)\n",
    "\n",
    "    # 训练集前向传递，返回对特定任务的概率向量/矩阵\n",
    "    def forwardRumor(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0]\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim) # view是为了适配gru的输入样式\n",
    "        gruOut, _ = self.shareGRU(embeddings, self.h0) # hs(seqLen, batch, numDirection * hiddenDim), ht(numLayers*numDirections, batch, hiddenDim)\n",
    "        ht = gruOut[gruOut.size()[0] - 1].view(self.batchSize, self.hiddenDim) # 取出最后一层的隐状态\n",
    "        p = self.vRumor(ht)\n",
    "        return p # 返回的概率矩阵是包含batch维度的size():(batch, numDirection)\n",
    "    \n",
    "    def forwardStance(self, sentences: torch.Tensor):\n",
    "        seqLen = sentences.size()[0]\n",
    "        embeddings = self.embeddingRumor(sentences).view(seqLen, self.batchSize, self.embeddingDim)\n",
    "        hs, _ = self.shareGRU(embeddings, self.h0)# hs(seqLen, batch, numDirection * hiddenDim)\n",
    "        ps = self.v1Stance(hs[0]) + self.vStance(hs)\n",
    "        return ps\n",
    "\n",
    "    # 更换计算设备\n",
    "    def set_device(self, device: torch.device) -> torch.nn.Module:\n",
    "        _model = self.to(device)\n",
    "        _model.device = device\n",
    "        return _model\n",
    "\n",
    "    # 保存模型\n",
    "    def save(self, path: str):\n",
    "        pass\n",
    "    # 加载模型\n",
    "    def load(self, path: str):\n",
    "        pass\n",
    "    \n",
    "mtus = MTUS(embeddingDim=100, hiddenDim=100, inputDim=maxLen,\n",
    "            numGRULayer=2, numRumorClass=3, numStanceClass=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0008, -0.0158, -0.0919]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "x = threads[0]\n",
    "rumorTag = \n",
    "p = mtus.forwardRumor(x)\n",
    "print(p)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(mtus.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
