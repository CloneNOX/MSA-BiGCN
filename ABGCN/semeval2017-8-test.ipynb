{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from data import collate\n",
    "from ABGCN import *\n",
    "\n",
    "from data import *\n",
    "dataset = semEval2017Dataset(\n",
    "    dataPath='../dataset/semeval2017-task8/', \n",
    "    type='train'\n",
    ")\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    '../dataset/glove/glove.twitter.27B.200d.gensim.txt',\n",
    "    binary=False\n",
    ")\n",
    "\n",
    "vectorSize = word2vec.vector_size\n",
    "word2vec.add_vectors([\"<start>\", \"<end>\", \"<unk>\"] ,np.random.randn(3, vectorSize))\n",
    "with open('../dataset/semeval2017-task8/wordList.json', 'r') as f:\n",
    "    content = f.read()\n",
    "wordList = [\"<unk>\", \"<start>\", \"<end>\"]\n",
    "wordList += (json.loads(content)).keys()\n",
    "word2index = {}\n",
    "index = 1\n",
    "for word in wordList:\n",
    "    if word in word2vec:\n",
    "        word2index[word] = index\n",
    "        index += 1\n",
    "\n",
    "dataset = semEval2017Dataset(\n",
    "    dataPath = '../dataset/semeval2017-task8/', \n",
    "    type = 'test'\n",
    ")\n",
    "loader = DataLoader(dataset, shuffle = True, num_workers = 4, collate_fn=collate)\n",
    "with open('../dataset/semeval2017-task8/' + 'trainSet.json', 'r') as f:\n",
    "    content = f.read()\n",
    "rawDataset = json.loads(content)\n",
    "label2IndexRumor = copy(rawDataset['label2IndexRumor'])\n",
    "label2IndexStance = copy(rawDataset['label2IndexStance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABGCN(\n",
      "  (embed): Embedding(7696, 200, padding_idx=0)\n",
      "  (wordAttention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (s2vFc): Linear(in_features=200, out_features=256, bias=True)\n",
      "  (biGCN): BiGCN(\n",
      "    (TDGCN): GCN(\n",
      "      (conv1): GCNConv(512, 512)\n",
      "      (conv2): GCNConv(1024, 512)\n",
      "    )\n",
      "    (BUGCN): GCN(\n",
      "      (conv1): GCNConv(512, 512)\n",
      "      (conv2): GCNConv(1024, 512)\n",
      "    )\n",
      "    (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
      "  )\n",
      "  (RumorFc): Linear(in_features=2048, out_features=3, bias=True)\n",
      "  (stanceAttention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (stanceFc): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = ABGCN(\n",
    "    word2vec = word2vec,\n",
    "    word2index = word2index,\n",
    "    s2vDim = 256,\n",
    "    gcnHiddenDim = 512,\n",
    "    rumorFeatureDim = 512,\n",
    "    numRumorTag = len(label2IndexRumor),\n",
    "    numStanceTag = len(label2IndexStance),\n",
    "    dropout = 0.2)\n",
    "model = model.set_device(device)\n",
    "model.load('./model/model.pt')\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average joint-loss: 44.079887\n",
      "rumor detection:\n",
      "accuracy: 0.392857, micro-f1: 0.392857, macro-f1: 0.390324\n",
      "stance analyze:\n",
      "accuracy: 0.553861, micro-f1: 0.553861, macro-f1: 0.300267\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from sklearn.metrics import f1_score\n",
    "model.eval()\n",
    "rumorTrue = []\n",
    "rumorPre = []\n",
    "stanceTrue = []\n",
    "stancePre = []\n",
    "totalLoss = 0.\n",
    "for thread in loader:\n",
    "    rumorTag = thread['rumorTag'].to(device)\n",
    "    rumorTrue += thread['rumorTag'].tolist()\n",
    "    stanceTag = thread['stanceTag'].to(device)\n",
    "    stanceTrue += thread['stanceTag'].tolist()\n",
    "\n",
    "    nodeText = thread['nodeText']\n",
    "    for i in range(len(nodeText)):\n",
    "        indexList = []\n",
    "        for word in nodeText[i]:\n",
    "            if word in word2index:\n",
    "                indexList.append(word2index[word])\n",
    "            elif word != '':\n",
    "                indexList.append(word2index['<unk>'])\n",
    "        nodeText[i] = torch.IntTensor(indexList).to(device)\n",
    "    nodeText = pad_sequence(nodeText, padding_value=0, batch_first=True)\n",
    "    thread['nodeText'] = nodeText\n",
    "    \n",
    "    rumorPredict, stancePredict = model.forward(thread)\n",
    "    loss = loss_func(rumorPredict, rumorTag) + loss_func(stancePredict, stanceTag)\n",
    "    totalLoss += loss\n",
    "\n",
    "    rumorPredict = softmax(rumorPredict, dim=1)\n",
    "    rumorPre += rumorPredict.max(dim=1)[1].tolist()\n",
    "    stancePredict = softmax(stancePredict, dim=1)\n",
    "    stancePre += stancePredict.max(dim=1)[1].tolist()\n",
    "\n",
    "microF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='micro')\n",
    "macroF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='macro')\n",
    "accRumor = (np.array(rumorTrue) == np.array(rumorPre)).sum() / len(rumorPre)\n",
    "microF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2,3], average='micro')\n",
    "macroF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2,3], average='macro')\n",
    "accStance = (np.array(stanceTrue) == np.array(stancePre)).sum() / len(stancePre)\n",
    "\n",
    "print('average joint-loss: {:f}'.format(totalLoss / len(loader)))\n",
    "print('rumor detection:')\n",
    "print('accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    accRumor, \n",
    "    microF1Rumor, \n",
    "    macroF1Rumor\n",
    "))\n",
    "print('stance analyze:')\n",
    "print('accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    accStance, \n",
    "    microF1Stance, \n",
    "    macroF1Stance\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7643d6338a47b6278c24a646f58c2f1853e9cc5d84629549f0ec76d46f16ce0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
