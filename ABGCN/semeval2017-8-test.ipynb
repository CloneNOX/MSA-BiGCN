{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data..."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import numpy as np\n",
    "from data import *\n",
    "from ABGCN import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import *\n",
    "from random import randint, shuffle\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "import sys\n",
    "\n",
    "print('preparing data...', end='')\n",
    "dataset = semEval2017Dataset(dataPath = '../dataset/semeval2017-task8/', \n",
    "                                type = 'test',\n",
    "                                w2vPath = '../dataset/glove/',\n",
    "                                w2vDim = 100)\n",
    "loader = DataLoader(dataset, shuffle=True)\n",
    "with open('../dataset/semeval2017-task8/' + 'testSet.json', 'r') as f:\n",
    "        content = f.read()\n",
    "rawDataset = json.loads(content)\n",
    "label2IndexRumor = copy(rawDataset['label2IndexRumor'])\n",
    "label2IndexStance = copy(rawDataset['label2IndexStance'])\n",
    "del rawDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor detection:\n",
      "average loss: 0.188951, accuracy: 1.000000, micro-f1: 1.000000, macro-f1: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = ABGCN(w2vDim = 100,\n",
    "              s2vDim = 128,\n",
    "              gcnHiddenDim = 128,\n",
    "              rumorFeatureDim = 128,\n",
    "              numRumorTag = len(label2IndexRumor),\n",
    "              numStanceTag = len(label2IndexStance),\n",
    "              s2vMethon = 'l')\n",
    "model = model.set_device(device)\n",
    "model.load('./model/model.pt')\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "rumorTrue = []\n",
    "rumorPre = []\n",
    "totalLoss = 0.\n",
    "\n",
    "model.eval()\n",
    "for data in tqdm(iter(loader), desc=\"[epoch {:d}, rumor]\".format(1), leave=False, ncols=100):\n",
    "    # 抹除dataloader生成batch时对数据的升维\n",
    "    data['threadId'] = data['threadId'][0]\n",
    "    data['threadIndex'] = data['threadIndex'][0]\n",
    "    for i in range(len(data['nodeFeature'])):\n",
    "        data['nodeFeature'][i] = data['nodeFeature'][i].view((data['nodeFeature'][i].shape[1], data['nodeFeature'][i].shape[2]))\n",
    "    data['edgeIndexTD'] = data['edgeIndexTD'].view((data['edgeIndexTD'].shape[1], data['edgeIndexTD'].shape[2]))\n",
    "    data['edgeIndexBU'] = data['edgeIndexBU'].view((data['edgeIndexBU'].shape[1], data['edgeIndexBU'].shape[2]))\n",
    "    data['rumorTag'] = data['rumorTag'].view((data['rumorTag'].shape[1]))\n",
    "    data['stanceTag'] = data['stanceTag'].view((data['stanceTag'].shape[1]))\n",
    "    rumorTag = data['rumorTag'].to(device)\n",
    "    rumorTrue += data['rumorTag'].tolist()\n",
    "\n",
    "    p = model.forwardRumor(data)\n",
    "    loss = loss_func(p, rumorTag)\n",
    "    totalLoss += loss\n",
    "    \n",
    "    p = softmax(p, dim=1)\n",
    "    rumorPre += p.max(dim=1)[1].tolist()\n",
    "microF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='micro')\n",
    "macroF1Rumor = f1_score(rumorTrue, rumorPre, labels=[0,1,2], average='macro')\n",
    "accuracyRumor = (np.array(rumorTrue) == np.array(rumorPre)).sum() / len(rumorPre)\n",
    "print('rumor detection:')\n",
    "print('average loss: {:f}, accuracy: {:f}, micro-f1: {:f}, macro-f1: {:f}'.format(\n",
    "    totalLoss / len(loader), accuracyRumor, microF1Rumor, macroF1Rumor\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7643d6338a47b6278c24a646f58c2f1853e9cc5d84629549f0ec76d46f16ce0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
