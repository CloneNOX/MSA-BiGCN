{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "dataset = semEval2017Dataset(\n",
    "    dataPath='../dataset/semeval2017-task8/', \n",
    "    type='train'\n",
    ")\n",
    "glove25d = KeyedVectors.load_word2vec_format(\n",
    "    '../dataset/glove/glove.twitter.27B.25d.gensim.txt',\n",
    "    binary=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21294 ,  0.31035 ,  0.17694 ,  0.87498 ,  0.067926,  0.59171 ,\n",
       "       -0.098218,  1.5896  , -0.428   , -1.3655  , -0.15278 , -2.501   ,\n",
       "       -5.5652  , -0.10232 ,  0.39577 ,  0.1555  , -0.55181 ,  0.34671 ,\n",
       "       -0.57379 , -0.30717 ,  0.043623, -0.39707 ,  0.64551 , -0.33537 ,\n",
       "        0.020467], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSize = len(glove25d) + 3\n",
    "vectorSize = glove25d.vector_size\n",
    "glove25d.add_vectors([\"<start>\", \"<end>\", \"<unk>\"] ,np.random.randn(3, vectorSize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data import collate\n",
    "cls = torch.randn(25).tolist()\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    collate_fn = lambda x: collate(x, glove25d, cls)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ABGCN import *\n",
    "from torch import optim\n",
    "model = ABGCN(\n",
    "    w2vDim = 25,\n",
    "    s2vDim = 64, # 使用的句嵌入的维度\n",
    "    gcnHiddenDim = 64, # GCN隐藏层的维度（GCNconv1的输出维度）\n",
    "    rumorFeatureDim = 64, # GCN输出层的维度\n",
    "    numRumorTag = 3, # 谣言标签种类数\n",
    "    numStanceTag = 4, # 立场标签种类数\n",
    "    numHeads = 5\n",
    ")\n",
    "device = torch.device('cpu')\n",
    "model = model.set_device(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 29, 25])\n",
      "torch.Size([7, 4])\n"
     ]
    }
   ],
   "source": [
    "for data in loader:\n",
    "    print(data['nodeFeature'].shape)\n",
    "\n",
    "    nodeFeature = model.forwardStance(data)\n",
    "\n",
    "    print(nodeFeature.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "totalLoss = 0.\n",
    "testdata = dataset[0]\n",
    "for data in tqdm(iter(loader), \n",
    "                 desc=\"[epoch {:d}, rumor]\".format(1),\n",
    "                 leave=False, \n",
    "                 ncols=100):\n",
    "\n",
    "                 \n",
    "    optimizer.zero_grad()\n",
    "    p = model.forwardRumor(data)\n",
    "    loss = loss_func(p, rumorTag)\n",
    "    totalLoss += loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    p = softmax(p, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8827, grad_fn=<DivBackward0>) 0.3664517167458828 0.6809815950920245\n",
      "tensor(0.8805, grad_fn=<DivBackward0>) 0.3739524186044866 0.6835771590372818\n",
      "tensor(0.8814, grad_fn=<DivBackward0>) 0.37313296977890675 0.6885323265691364\n",
      "tensor(0.8790, grad_fn=<DivBackward0>) 0.3692088799601987 0.6826333176026428\n",
      "tensor(0.8803, grad_fn=<DivBackward0>) 0.35746072011779106 0.683341198678622\n",
      "tensor(0.8761, grad_fn=<DivBackward0>) 0.37023320623264133 0.6798017932987258\n",
      "tensor(0.8817, grad_fn=<DivBackward0>) 0.36673998929704593 0.6864086833411986\n",
      "tensor(0.8808, grad_fn=<DivBackward0>) 0.38842461678550755 0.6882963662104766\n",
      "tensor(0.8771, grad_fn=<DivBackward0>) 0.3722053150436 0.6847569608305805\n",
      "tensor(0.8797, grad_fn=<DivBackward0>) 0.375022099724999 0.6864086833411986\n",
      "tensor(0.8785, grad_fn=<DivBackward0>) 0.365707365726919 0.6819254365266635\n",
      "tensor(0.8811, grad_fn=<DivBackward0>) 0.3664137676632411 0.6828692779613025\n",
      "tensor(0.8776, grad_fn=<DivBackward0>) 0.37172717601441924 0.6826333176026428\n",
      "tensor(0.8752, grad_fn=<DivBackward0>) 0.3702713673752448 0.683341198678622\n",
      "tensor(0.8787, grad_fn=<DivBackward0>) 0.3759228043546754 0.6854648419065597\n",
      "tensor(0.8796, grad_fn=<DivBackward0>) 0.37172230270271855 0.6845210004719208\n",
      "tensor(0.8786, grad_fn=<DivBackward0>) 0.3591289384809781 0.6802737140160453\n",
      "tensor(0.8781, grad_fn=<DivBackward0>) 0.36488633260345193 0.6828692779613025\n",
      "tensor(0.8807, grad_fn=<DivBackward0>) 0.36380069174933927 0.6798017932987258\n",
      "tensor(0.8790, grad_fn=<DivBackward0>) 0.3752279562630404 0.6828692779613025\n",
      "tensor(0.8758, grad_fn=<DivBackward0>) 0.38617907070540375 0.6852288815479\n",
      "tensor(0.8780, grad_fn=<DivBackward0>) 0.36909428044755344 0.6826333176026428\n",
      "tensor(0.8765, grad_fn=<DivBackward0>) 0.3750701132235137 0.6875884851344974\n",
      "tensor(0.8779, grad_fn=<DivBackward0>) 0.37227972364669515 0.684285040113261\n",
      "tensor(0.8746, grad_fn=<DivBackward0>) 0.3768636982375491 0.6835771590372818\n",
      "tensor(0.8790, grad_fn=<DivBackward0>) 0.3653287688266456 0.6819254365266635\n",
      "tensor(0.8748, grad_fn=<DivBackward0>) 0.36958151751377666 0.6871165644171779\n",
      "tensor(0.8772, grad_fn=<DivBackward0>) 0.3775589636999591 0.6852288815479\n",
      "tensor(0.8769, grad_fn=<DivBackward0>) 0.3779364320742422 0.6831052383199623\n",
      "tensor(0.8766, grad_fn=<DivBackward0>) 0.37948996374799804 0.682397357243983\n",
      "tensor(0.8764, grad_fn=<DivBackward0>) 0.3641066126548659 0.6873525247758376\n",
      "tensor(0.8755, grad_fn=<DivBackward0>) 0.3705576697722818 0.6802737140160453\n",
      "tensor(0.8763, grad_fn=<DivBackward0>) 0.3772941142402395 0.6854648419065597\n",
      "tensor(0.8770, grad_fn=<DivBackward0>) 0.3625869083581167 0.6816894761680038\n",
      "tensor(0.8758, grad_fn=<DivBackward0>) 0.3805170585798587 0.6866446436998584\n",
      "tensor(0.8765, grad_fn=<DivBackward0>) 0.37528544232456046 0.6859367626238791\n",
      "tensor(0.8719, grad_fn=<DivBackward0>) 0.3704789889578385 0.6831052383199623\n",
      "tensor(0.8791, grad_fn=<DivBackward0>) 0.37129321589193964 0.686172722982539\n",
      "tensor(0.8746, grad_fn=<DivBackward0>) 0.38993458699631744 0.6854648419065597\n",
      "tensor(0.8762, grad_fn=<DivBackward0>) 0.36571041313583463 0.684285040113261\n",
      "tensor(0.8752, grad_fn=<DivBackward0>) 0.3736177125717387 0.6840490797546013\n",
      "tensor(0.8774, grad_fn=<DivBackward0>) 0.36940164239440626 0.6866446436998584\n",
      "tensor(0.8712, grad_fn=<DivBackward0>) 0.3748540667506185 0.6908919301557338\n",
      "tensor(0.8719, grad_fn=<DivBackward0>) 0.37500384035390866 0.6904200094384143\n",
      "tensor(0.8775, grad_fn=<DivBackward0>) 0.38196216166127295 0.6866446436998584\n",
      "tensor(0.8749, grad_fn=<DivBackward0>) 0.3703954920842973 0.686172722982539\n",
      "tensor(0.8765, grad_fn=<DivBackward0>) 0.3738230543599054 0.6859367626238791\n",
      "tensor(0.8731, grad_fn=<DivBackward0>) 0.37484167876408425 0.6845210004719208\n",
      "tensor(0.8743, grad_fn=<DivBackward0>) 0.38085522936893457 0.6897121283624351\n",
      "tensor(0.8716, grad_fn=<DivBackward0>) 0.3888881099501785 0.6868806040585181\n",
      "tensor(0.8765, grad_fn=<DivBackward0>) 0.3676449473016481 0.6880604058518169\n",
      "tensor(0.8749, grad_fn=<DivBackward0>) 0.3777490471783267 0.6859367626238791\n",
      "tensor(0.8754, grad_fn=<DivBackward0>) 0.37963925764162054 0.6878244454931571\n",
      "tensor(0.8765, grad_fn=<DivBackward0>) 0.3726957724852102 0.6873525247758376\n",
      "tensor(0.8738, grad_fn=<DivBackward0>) 0.37867732753445293 0.6849929211892402\n",
      "tensor(0.8713, grad_fn=<DivBackward0>) 0.37787280752454494 0.684285040113261\n",
      "tensor(0.8724, grad_fn=<DivBackward0>) 0.37445962213268036 0.6915998112317131\n",
      "tensor(0.8737, grad_fn=<DivBackward0>) 0.37568992752104496 0.6857008022652195\n",
      "tensor(0.8741, grad_fn=<DivBackward0>) 0.37749150488189104 0.6875884851344974\n",
      "tensor(0.8715, grad_fn=<DivBackward0>) 0.37056741259936776 0.6864086833411986\n",
      "tensor(0.8744, grad_fn=<DivBackward0>) 0.3820489770056984 0.6866446436998584\n",
      "tensor(0.8726, grad_fn=<DivBackward0>) 0.38731031867031296 0.6878244454931571\n",
      "tensor(0.8725, grad_fn=<DivBackward0>) 0.3784106167090905 0.6887682869277961\n",
      "tensor(0.8745, grad_fn=<DivBackward0>) 0.3796628560442541 0.6887682869277961\n",
      "tensor(0.8730, grad_fn=<DivBackward0>) 0.3814891972988691 0.6885323265691364\n",
      "tensor(0.8683, grad_fn=<DivBackward0>) 0.372345195110487 0.6835771590372818\n",
      "tensor(0.8740, grad_fn=<DivBackward0>) 0.3736508388616288 0.6840490797546013\n",
      "tensor(0.8770, grad_fn=<DivBackward0>) 0.3607980475747312 0.6764983482774893\n",
      "tensor(0.8716, grad_fn=<DivBackward0>) 0.3872921214208912 0.6887682869277961\n",
      "tensor(0.8738, grad_fn=<DivBackward0>) 0.3764730453817938 0.682397357243983\n",
      "tensor(0.8732, grad_fn=<DivBackward0>) 0.368074872829231 0.681453515809344\n",
      "tensor(0.8717, grad_fn=<DivBackward0>) 0.3770944577497276 0.686172722982539\n",
      "tensor(0.8727, grad_fn=<DivBackward0>) 0.3910794684646453 0.6882963662104766\n",
      "tensor(0.8720, grad_fn=<DivBackward0>) 0.36477621728801435 0.6875884851344974\n",
      "tensor(0.8692, grad_fn=<DivBackward0>) 0.3834603456678686 0.6908919301557338\n",
      "tensor(0.8704, grad_fn=<DivBackward0>) 0.38263249340068617 0.6890042472864559\n",
      "tensor(0.8697, grad_fn=<DivBackward0>) 0.3749468566788247 0.684285040113261\n",
      "tensor(0.8713, grad_fn=<DivBackward0>) 0.38246582857825684 0.6906559697970741\n",
      "tensor(0.8724, grad_fn=<DivBackward0>) 0.39006725593326724 0.6875884851344974\n",
      "tensor(0.8716, grad_fn=<DivBackward0>) 0.3828527702005222 0.6880604058518169\n",
      "tensor(0.8747, grad_fn=<DivBackward0>) 0.38189252452038064 0.6911278905143936\n",
      "tensor(0.8698, grad_fn=<DivBackward0>) 0.39180747568350144 0.6892402076451156\n",
      "tensor(0.8747, grad_fn=<DivBackward0>) 0.36897985979118875 0.684285040113261\n",
      "tensor(0.8724, grad_fn=<DivBackward0>) 0.38354571218009814 0.6878244454931571\n",
      "tensor(0.8716, grad_fn=<DivBackward0>) 0.37287212600136743 0.6840490797546013\n",
      "tensor(0.8713, grad_fn=<DivBackward0>) 0.39020345309310567 0.6871165644171779\n",
      "tensor(0.8707, grad_fn=<DivBackward0>) 0.3829455047795604 0.6882963662104766\n",
      "tensor(0.8703, grad_fn=<DivBackward0>) 0.38618663799012853 0.6887682869277961\n",
      "tensor(0.8710, grad_fn=<DivBackward0>) 0.3735999869899609 0.6890042472864559\n",
      "tensor(0.8689, grad_fn=<DivBackward0>) 0.38467699413441925 0.6901840490797546\n",
      "tensor(0.8706, grad_fn=<DivBackward0>) 0.38943578027776193 0.6880604058518169\n",
      "tensor(0.8709, grad_fn=<DivBackward0>) 0.37676529182607044 0.6887682869277961\n",
      "tensor(0.8709, grad_fn=<DivBackward0>) 0.38379043224237375 0.6911278905143936\n",
      "tensor(0.8703, grad_fn=<DivBackward0>) 0.3786725892644105 0.6899480887210948\n",
      "tensor(0.8704, grad_fn=<DivBackward0>) 0.3768731967035838 0.6923076923076923\n",
      "tensor(0.8698, grad_fn=<DivBackward0>) 0.39121083333080636 0.6894761680037753\n",
      "tensor(0.8702, grad_fn=<DivBackward0>) 0.37906273637520704 0.6890042472864559\n",
      "tensor(0.8697, grad_fn=<DivBackward0>) 0.3773202851470814 0.6899480887210948\n",
      "tensor(0.8680, grad_fn=<DivBackward0>) 0.3838574431491285 0.6906559697970741\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import softmax\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    stanceTrue = []\n",
    "    stancePre = []\n",
    "    totalLoss = 0.\n",
    "\n",
    "    for data in loader:\n",
    "        stanceTag = data['stanceTag']\n",
    "        stanceTrue += data['stanceTag'].tolist()\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        p = model.forwardStance(data)\n",
    "        loss = loss_func(p, stanceTag)\n",
    "        totalLoss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        p = softmax(p, dim=1)\n",
    "        stancePre += p.max(dim=1)[1].tolist()\n",
    "        \n",
    "    accuracy = (np.array(stancePre) == np.array(stanceTrue)).sum() / len(stanceTrue)\n",
    "    macroF1Stance = f1_score(stanceTrue, stancePre, labels=[0,1,2,3], average='macro')\n",
    "    print(totalLoss / len(loader), macroF1Stance, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53024653744be1c7fdb50f623c21bc7cbc066eeadd60abd98245bb69a9f2fbe7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('xsr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
