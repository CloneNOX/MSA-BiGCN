{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "non-rumor charliehebdo: 100%|██████████| 1622/1622 [08:25<00:00,  3.21it/s]\n",
      "rumor charliehebdo: 100%|██████████| 459/459 [02:06<00:00,  3.64it/s]\n",
      "non-rumor ebola-essien: 0it [00:00, ?it/s]\n",
      "rumor ebola-essien: 100%|██████████| 15/15 [00:03<00:00,  3.76it/s]\n",
      "non-rumor ferguson: 100%|██████████| 860/860 [04:51<00:00,  2.95it/s]\n",
      "rumor ferguson: 100%|██████████| 285/285 [01:46<00:00,  2.67it/s]\n",
      "non-rumor germanwings-crash: 100%|██████████| 231/231 [00:35<00:00,  6.47it/s]\n",
      "rumor germanwings-crash: 100%|██████████| 239/239 [00:45<00:00,  5.25it/s]\n",
      "non-rumor gurlitt: 100%|██████████| 78/78 [00:02<00:00, 27.62it/s]\n",
      "rumor gurlitt: 100%|██████████| 62/62 [00:03<00:00, 20.49it/s]\n",
      "non-rumor ottawashooting: 100%|██████████| 420/420 [01:37<00:00,  4.30it/s]\n",
      "rumor ottawashooting: 100%|██████████| 471/471 [01:54<00:00,  4.13it/s]\n",
      "non-rumor prince-toronto: 100%|██████████| 4/4 [00:00<00:00, 21.51it/s]\n",
      "rumor prince-toronto: 100%|██████████| 230/230 [00:20<00:00, 11.01it/s]\n",
      "non-rumor putinmissing: 100%|██████████| 113/113 [00:07<00:00, 15.04it/s]\n",
      "rumor putinmissing: 100%|██████████| 127/127 [00:11<00:00, 11.13it/s]\n",
      "non-rumor sydneysiege: 100%|██████████| 699/699 [04:12<00:00,  2.76it/s]\n",
      "rumor sydneysiege: 100%|██████████| 523/523 [01:36<00:00,  5.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from process import ProcessRNRDataset\n",
    "threadId, postId, threadTag, structures, posts = ProcessRNRDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./thread_id.txt', 'w') as f:\n",
    "    for id in threadId:\n",
    "        f.write(id + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./post_id.txt', 'w') as f:\n",
    "    for id in postId:\n",
    "        f.write(id + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./thread_label.txt', 'w') as f:\n",
    "    for id in threadId:\n",
    "        f.write(str(threadTag[id]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./structures.json', 'w') as f:\n",
    "    json.dump(structures, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./posts.json', 'w') as f:\n",
    "    json.dump(posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train thread num:  5354\n",
      "train post num:  87078\n",
      "train tag num in N-T-F-U: 3367 888 533 566\n",
      "test thread num:  1071\n",
      "test post num:  17504\n",
      "test tag num in N-T-F-U: 656 179 105 131\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffle(threadId)\n",
    "bound = len(threadId) * 5 // 6\n",
    "\n",
    "trainThreadId = threadId[0:bound]\n",
    "trainPostId = []\n",
    "for id in trainThreadId:\n",
    "    for pid in posts[id]:\n",
    "        trainPostId.append(pid)\n",
    "trainTag = {}\n",
    "for id in trainThreadId:\n",
    "    trainTag[id] = threadTag[id]\n",
    "trainStructures = {}\n",
    "for id in trainThreadId:\n",
    "    trainStructures[id] = structures[id]\n",
    "trainPosts = {}\n",
    "for id in trainThreadId:\n",
    "    for pid in posts[id]:\n",
    "        trainPosts[pid] = posts[id][pid]\n",
    "\n",
    "testThreadId = threadId[bound:]\n",
    "testPostId = []\n",
    "for id in testThreadId:\n",
    "    for pid in posts[id]:\n",
    "        testPostId.append(pid)\n",
    "testTag = {}\n",
    "for id in testThreadId:\n",
    "    testTag[id] = threadTag[id]\n",
    "testStructures = {}\n",
    "for id in testThreadId:\n",
    "    testStructures[id] = structures[id]\n",
    "testPosts = {}\n",
    "for id in testThreadId:\n",
    "    for pid in posts[id]:\n",
    "        testPosts[pid] = posts[id][pid]\n",
    "\n",
    "\n",
    "print('train thread num: ', len(trainThreadId))\n",
    "print('train post num: ', len(trainPostId))\n",
    "label = [0,0,0,0]\n",
    "for id in trainThreadId:\n",
    "    label[trainTag[id]] += 1\n",
    "print('train tag num in N-T-F-U:', label[0], label[1], label[2], label[3])\n",
    "\n",
    "print('test thread num: ', len(testThreadId))\n",
    "print('test post num: ', len(testPostId))\n",
    "label = [0,0,0,0]\n",
    "for id in testThreadId:\n",
    "    label[testTag[id]] += 1\n",
    "print('test tag num in N-T-F-U:', label[0], label[1], label[2], label[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = {}\n",
    "for key in trainPosts:\n",
    "    text = trainPosts[key]['text']\n",
    "    words = fixText(text)\n",
    "    for word in words.split(' '):\n",
    "        if word not in wordList:\n",
    "            wordList[word] = 1\n",
    "    trainPosts[key]['text'] = words\n",
    "trainSet = {\n",
    "    'threadIds': trainThreadId,\n",
    "    'postIds': trainPostId,\n",
    "    'rumorTags': trainTag,\n",
    "    'structures': trainStructures,\n",
    "    'posts': trainPosts,\n",
    "    'label2Index': label2Index\n",
    "}\n",
    "testSet = {\n",
    "    'threadIds': testThreadId,\n",
    "    'postIds': testPostId,\n",
    "    'rumorTags': testTag,\n",
    "    'structures': testStructures,\n",
    "    'posts': testPosts,\n",
    "    'label2Index': label2Index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78405\n"
     ]
    }
   ],
   "source": [
    "with open('trainSet.json', 'w') as f:\n",
    "    f.write(json.dumps(trainSet))\n",
    "# with open('devSet.json', 'w') as f:\n",
    "#     f.write(json.dumps(devSet))\n",
    "with open('testSet.json', 'w') as f:\n",
    "    f.write(json.dumps(testSet))\n",
    "with open('wordList.json', 'w') as f:\n",
    "    f.write(json.dumps(wordList))\n",
    "print(len(wordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53024653744be1c7fdb50f623c21bc7cbc066eeadd60abd98245bb69a9f2fbe7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('xsr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
