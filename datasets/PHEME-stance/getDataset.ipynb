{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "charliehebdo non-rumor: 100%|██████████| 1622/1622 [00:02<00:00, 643.69it/s]\n",
      "charliehebdo rumor: 100%|██████████| 459/459 [00:00<00:00, 775.00it/s]\n",
      "ebola-essien non-rumor: 0it [00:00, ?it/s]\n",
      "ebola-essien rumor: 100%|██████████| 15/15 [00:00<00:00, 776.70it/s]\n",
      "ferguson non-rumor: 100%|██████████| 860/860 [00:01<00:00, 616.78it/s]\n",
      "ferguson rumor: 100%|██████████| 285/285 [00:00<00:00, 515.49it/s]\n",
      "germanwings-crash non-rumor: 100%|██████████| 231/231 [00:00<00:00, 1356.71it/s]\n",
      "germanwings-crash rumor: 100%|██████████| 239/239 [00:00<00:00, 1157.08it/s]\n",
      "gurlitt non-rumor: 100%|██████████| 78/78 [00:00<00:00, 7828.56it/s]\n",
      "gurlitt rumor: 100%|██████████| 62/62 [00:00<00:00, 5516.25it/s]\n",
      "ottawashooting non-rumor: 100%|██████████| 420/420 [00:00<00:00, 906.86it/s]\n",
      "ottawashooting rumor: 100%|██████████| 471/471 [00:00<00:00, 901.10it/s]\n",
      "prince-toronto non-rumor: 100%|██████████| 4/4 [00:00<00:00, 4056.39it/s]\n",
      "prince-toronto rumor: 100%|██████████| 230/230 [00:00<00:00, 2738.54it/s]\n",
      "putinmissing non-rumor: 100%|██████████| 113/113 [00:00<00:00, 3645.76it/s]\n",
      "putinmissing rumor: 100%|██████████| 127/127 [00:00<00:00, 2851.73it/s]\n",
      "sydneysiege non-rumor: 100%|██████████| 699/699 [00:01<00:00, 585.05it/s]\n",
      "sydneysiege rumor: 100%|██████████| 523/523 [00:00<00:00, 750.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from process import ProcessRNRDataset\n",
    "threadId, postId, threadTag, structures, posts = ProcessRNRDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all/thread_id.txt', 'w') as f:\n",
    "    for id in threadId:\n",
    "        f.write(id + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all/post_id.txt', 'w') as f:\n",
    "    for id in postId:\n",
    "        f.write(id + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all/thread_label.txt', 'w') as f:\n",
    "    for id in threadId:\n",
    "        f.write(str(threadTag[id]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./all/structures.json', 'w') as f:\n",
    "    json.dump(structures, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./all/posts.json', 'w') as f:\n",
    "    json.dump(posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from process import label2Index\n",
    "with open('./rumorCategory.json', 'w') as f:\n",
    "    json.dump(label2Index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104582\n",
      "104582\n"
     ]
    }
   ],
   "source": [
    "print(len(postId))\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in postId:\n",
    "    try:\n",
    "        a = posts[id]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./all/posts.json', 'w') as f:\n",
    "    json.dump(posts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充的PHEME立场标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('./stanceCategory.json', 'r') as f:\n",
    "    stance2label = json.load(f)\n",
    "with open('./all/thread_id.txt', 'r') as f:\n",
    "    thread_ids = [id.strip() for id in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6425"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thread_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./all/all-PHEME-stance-semeval-set.xlsx')\n",
    "df['id'] = df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all/post_label.txt', 'w') as fout:\n",
    "    stances = {row['id']:row['stance'] for _, row in df.iterrows()}\n",
    "    posts = []\n",
    "    with open('./all/post_id.txt', 'r') as fposts:\n",
    "        posts += [post.strip() for post in fposts.readlines()]\n",
    "    for post in posts:\n",
    "        if post not in stances:\n",
    "            fout.write(str(stance2label['comment']) + '\\n')\n",
    "        elif post in thread_ids:\n",
    "            fout.write(str(stance2label['support']) + '\\n')\n",
    "        else:\n",
    "            fout.write(str(stance2label[stances[post]]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计各个事件的立场标签情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import label2Index, index2Label, DATA_PATH\n",
    "\n",
    "posts = []\n",
    "stances = []\n",
    "\n",
    "with open('./all/post_id.txt', 'r') as f:\n",
    "    posts += [post.strip() for post in f.readlines()]\n",
    "with open('./all/post_label.txt', 'r') as f:\n",
    "    stances += [int(stance.strip()) for stance in f.readlines()]\n",
    "\n",
    "post_id2stance = {post:stance for post, stance in zip(posts, stances)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charliehebdo', 'ebola-essien', 'ferguson', 'germanwings-crash', 'gurlitt', 'ottawashooting', 'prince-toronto', 'putinmissing', 'sydneysiege', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "eventName = os.listdir(DATA_PATH)\n",
    "print(eventName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eventName:  charliehebdo\n",
      "会话数量:  2079\n",
      "推文数量:  38268\n",
      "谣言标签：T: true-rumor: 193 , false-rumor: 116 , unverified-rumor 149 , F: 1621\n",
      "立场标签: S: 3296 , Q: 1188 , D: 1117 , C: 32667\n",
      "eventName:  ebola-essien\n",
      "会话数量:  14\n",
      "推文数量:  226\n",
      "谣言标签：T: true-rumor: 0 , false-rumor: 14 , unverified-rumor 0 , F: 0\n",
      "立场标签: S: 20 , Q: 2 , D: 29 , C: 175\n",
      "eventName:  ferguson\n",
      "会话数量:  1143\n",
      "推文数量:  24175\n",
      "谣言标签：T: true-rumor: 10 , false-rumor: 8 , unverified-rumor 266 , F: 859\n",
      "立场标签: S: 2431 , Q: 1121 , D: 888 , C: 19735\n",
      "eventName:  germanwings-crash\n",
      "会话数量:  469\n",
      "推文数量:  4489\n",
      "谣言标签：T: true-rumor: 94 , false-rumor: 111 , unverified-rumor 33 , F: 231\n",
      "立场标签: S: 746 , Q: 279 , D: 137 , C: 3327\n",
      "eventName:  gurlitt\n",
      "会话数量:  138\n",
      "推文数量:  179\n",
      "谣言标签：T: true-rumor: 59 , false-rumor: 0 , unverified-rumor 2 , F: 77\n",
      "立场标签: S: 141 , Q: 1 , D: 0 , C: 37\n",
      "eventName:  ottawashooting\n",
      "会话数量:  890\n",
      "推文数量:  12284\n",
      "谣言标签：T: true-rumor: 329 , false-rumor: 72 , unverified-rumor 69 , F: 420\n",
      "立场标签: S: 1302 , Q: 576 , D: 373 , C: 10033\n",
      "eventName:  prince-toronto\n",
      "会话数量:  233\n",
      "推文数量:  902\n",
      "谣言标签：T: true-rumor: 0 , false-rumor: 222 , unverified-rumor 7 , F: 4\n",
      "立场标签: S: 253 , Q: 57 , D: 9 , C: 583\n",
      "eventName:  putinmissing\n",
      "会话数量:  238\n",
      "推文数量:  835\n",
      "谣言标签：T: true-rumor: 0 , false-rumor: 9 , unverified-rumor 117 , F: 112\n",
      "立场标签: S: 263 , Q: 34 , D: 23 , C: 515\n",
      "eventName:  sydneysiege\n",
      "会话数量:  1221\n",
      "推文数量:  23996\n",
      "谣言标签：T: true-rumor: 382 , false-rumor: 86 , unverified-rumor 54 , F: 699\n",
      "立场标签: S: 1923 , Q: 1011 , D: 943 , C: 20119\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from process import strTime2Timestamp\n",
    "from convert_veracity_annotations import convert_annotations\n",
    "import numpy as np\n",
    "\n",
    "for event in eventName:\n",
    "    if '.' in event: continue\n",
    "    print('eventName: ', event)\n",
    "    thread_id = []\n",
    "    post_id = []\n",
    "    thread_tag = {}\n",
    "    structures = {}\n",
    "    posts = {}\n",
    "\n",
    "    ids = os.listdir(os.path.join(DATA_PATH, event, 'non-rumours'))\n",
    "    for tid in ids:\n",
    "        if '.' in tid: continue\n",
    "        path = os.path.join(DATA_PATH, event, 'non-rumours', str(tid))\n",
    "\n",
    "        # source tweet id\n",
    "        thread_id.append(tid)\n",
    "        post_id.append(tid)\n",
    "\n",
    "        # thread tag(non-rumor)\n",
    "        thread_tag[tid] = 0\n",
    "\n",
    "        # structure\n",
    "        with open(os.path.join(path, 'structure.json'), 'r') as f:\n",
    "            content = f.read()\n",
    "        structures[tid] = json.loads(content)\n",
    "\n",
    "        pids = os.listdir(os.path.join(path, 'reactions'))\n",
    "        for pfname in pids:\n",
    "            if '._' not in pfname and '.json' in pfname:\n",
    "                pid = pfname[0:-5]\n",
    "                post_id.append(pid)\n",
    "\n",
    "\n",
    "    ids = os.listdir(os.path.join(DATA_PATH, event, 'rumours'))\n",
    "    for tid in ids:\n",
    "        if '.' in tid: continue\n",
    "        path = os.path.join(DATA_PATH, event, 'rumours', str(tid))\n",
    "        # id\n",
    "        thread_id.append(tid)\n",
    "        post_id.append(tid)\n",
    "        # tag\n",
    "        with open(os.path.join(path, 'annotation.json'), 'r') as f:\n",
    "            annotation = json.loads(f.read())\n",
    "            label = convert_annotations(annotation)\n",
    "        thread_tag[tid] = label2Index[label]\n",
    "        # structure\n",
    "        with open(os.path.join(path, 'structure.json'), 'r') as f:\n",
    "            content = f.read()\n",
    "        structures[tid] = json.loads(content)\n",
    "\n",
    "        pids = os.listdir(os.path.join(path, 'reactions'))\n",
    "        for pfname in pids:\n",
    "            if '._' not in pfname and '.json' in pfname:\n",
    "                pid = pfname[0:-5]\n",
    "                post_id.append(pid)      \n",
    "    \n",
    "    print('会话数量: ', len(thread_id))\n",
    "    print('推文数量: ', len(post_id))\n",
    "    thread_tag = np.array([int(thread_tag[id]) for id in thread_tag])\n",
    "    print('谣言标签：T: true-rumor:', (thread_tag == 1).sum(), ', false-rumor:', (thread_tag == 2).sum(),\\\n",
    "          ', unverified-rumor', (thread_tag == 3).sum(), ', F:', (thread_tag == 0).sum())\n",
    "    stances = np.array([int(post_id2stance[post]) for post in post_id])\n",
    "    print('立场标签: S:', (stances == 0).sum(), ', Q:', (stances == 1).sum(),\\\n",
    "          ', D:', (stances == 2).sum(), ', C:', (stances == 3).sum())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53024653744be1c7fdb50f623c21bc7cbc066eeadd60abd98245bb69a9f2fbe7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:bigcn]",
   "language": "python",
   "name": "conda-env-bigcn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
